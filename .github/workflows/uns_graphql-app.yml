# This workflow will install Python dependencies, run tests and lint with a single version of Python
# For more information see: https://help.github.com/actions/language-and-framework-guides/using-python-with-github-actions

name: UNS GraphQL Client

on:
  push:
    branches:
      - "**"
    paths:
      - "02_mqtt-cluster/**/*.py*"
      - "02_mqtt-cluster/pyproject.toml"
      - "02_mqtt-cluster/uv.lock"
      - "07_uns_graphql/**/*.py"
      - "07_uns_graphql/pyproject.toml"
      - "07_uns_graphql/uv.lock"
      - "07_uns_graphql/Dockerfile"
      - ".github/workflows/uns_graphql-app.yml"
      - ".github/include/**"

  pull_request:
    branches:
      - "**"
    paths:
      - "02_mqtt-cluster/**/*.py*"
      - "02_mqtt-cluster/pyproject.toml"
      - "02_mqtt-cluster/uv.lock"
      - "07_uns_graphql/**/*.py"
      - "07_uns_graphql/pyproject.toml"
      - "07_uns_graphql/uv.lock"
      - "07_uns_graphql/Dockerfile"
      - ".github/workflows/uns_graphql-app.yml"
      - ".github/include/**"

  workflow_dispatch:
    inputs:
      pytest_add_opts: # trunk-ignore(checkov/CKV_GHA_7)
        description: "additional pytest options"
        type: string

permissions:
  contents: read

jobs:
  generate_random_password:
    runs-on: ubuntu-latest
    outputs:
      neo4j_pwd: ${{ steps.random_strings.outputs.neo4j_pwd}}
      postgres_pwd: ${{ steps.random_strings.outputs.postgres_pwd}}
      uns_historian_pwd: ${{ steps.random_strings.outputs.uns_historian_pwd}}
      uns_kafka_cluster_id: ${{ steps.random_strings.outputs.uns_kafka_cluster_id}}
    steps:
      - id: random_strings
        run: |
          echo "neo4j_pwd=$(openssl rand -base64 32 | tr -dc '[:alnum:]')" >> $GITHUB_OUTPUT
          echo "postgres_pwd=$(openssl rand -base64 32 | tr -dc '[:alnum:]')" >> $GITHUB_OUTPUT
          echo "uns_historian_pwd=$(openssl rand -base64 32 | tr -dc '[:alnum:]')" >> $GITHUB_OUTPUT
          echo "uns_kafka_cluster_id=$(openssl rand -base64 32 | tr -dc '[:alnum:]')" >> $GITHUB_OUTPUT

  build_code:
    runs-on: ubuntu-latest
    needs: generate_random_password
    environment: dev
    env:
      UNS_mqtt__host: "localhost"
      UNS_mqtt__port: 1883
      UNS_graphdb__url: "bolt://localhost:7687"
      UNS_graphdb__username: "neo4j"
      UNS_graphdb__password: ${{ needs.generate_random_password.outputs.neo4j_pwd }}
      UNS_historian__hostname: "localhost"
      UNS_historian__database: "uns_historian"
      UNS_historian__table: "unifiednamespace"
      UNS_historian__username: "uns_dbuser"
      UNS_historian__password: ${{ needs.generate_random_password.outputs.uns_historian_pwd }}
      POSTGRES_PASSWORD: ${{ needs.generate_random_password.outputs.postgres_pwd }}
      UNS_kafka.config: "{ 'group.id' = 'uns_graphql', 'client.id' = 'uns_graphql_client', 'bootstrap.servers' ='localhost:9092' }"
      UNS_kafka_cluster_id: ${{ needs.generate_random_password.outputs.uns_kafka_cluster_id }}

    services:
      uns_mqtt:
        image: "emqx/emqx:latest"
        ports:
          # MQTT Ports
          - "1883:1883" # MQTT, unencrypted, unauthenticated
          - "1884:1884" # MQTT, unencrypted, authenticated
          # WebSocket Ports
          - "8080:8080" # MQTT over WebSockets, unencrypted, unauthenticated
          - "8090:8090" # MQTT over WebSockets, unencrypted, authenticated

      uns_graphdb:
        image: "neo4j:latest"
        ports:
          - "7474:7474"
          - "7687:7687"
        env:
          NEO4J_AUTH: neo4j/${{ env.UNS_graphdb__password }}
          apoc.export.file.enabled: true
          apoc.import.file.enabled: true
          apoc.import.file.use_neo4j_config: true
          NEO4J_PLUGINS: '["apoc"]'

      uns_timescaledb:
        image: "timescale/timescaledb:latest-pg16"
        ports:
          - "5432:5432"
        env:
          POSTGRES_PASSWORD: ${{ env.POSTGRES_PASSWORD }}

      uns_kafka:
        image: "apache/kafka:latest"
        ports:
          - "9092:9092"
        env:
          KAFKA_BROKER_ID: 1
          KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT,CONTROLLER:PLAINTEXT"
          KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://uns_kafka:29092,PLAINTEXT_HOST://localhost:9092"
          KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
          KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
          KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
          KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
          KAFKA_PROCESS_ROLES: "broker,controller"
          KAFKA_NODE_ID: 1
          KAFKA_CONTROLLER_QUORUM_VOTERS: "1@uns_kafka:29093"
          KAFKA_LISTENERS: "PLAINTEXT://uns_kafka:29092,CONTROLLER://uns_kafka:29093,PLAINTEXT_HOST://0.0.0.0:9092"
          KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
          KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
          KAFKA_LOG_DIRS: /tmp/kraft-combined-logs
          CLUSTER_ID: "$(UNS_kafka_cluster_id) "

    steps:
      - uses: actions/checkout@v6

      - name: Setup with python environment
        uses: ./.github/include/setup_python/
        with:
          module: 07_uns_graphql
      - name: Create Database for Integration Testing
        env:
          POSTGRES_PASSWORD: ${{ env.POSTGRES_PASSWORD }}
          UNS_historian__password: ${{ env.UNS_historian__password }}
        run: |
          echo "CREATE database $UNS_historian__database;
          \c $UNS_historian__database;
          CREATE EXTENSION IF NOT EXISTS timescaledb;

          CREATE ROLE $UNS_historian__username
          LOGIN
          PASSWORD '$UNS_historian__password';

          ALTER DATABASE $UNS_historian__database OWNER TO $UNS_historian__username;
          " | PGPASSWORD=${POSTGRES_PASSWORD} psql -h ${UNS_historian__hostname} -U postgres  -p 5432

          echo "CREATE TABLE $UNS_historian__table (
          time TIMESTAMPTZ NOT NULL,
          topic text NOT NULL,
          client_id text,
          mqtt_msg JSONB, 
          CONSTRAINT unique_event UNIQUE (time, topic, client_id, mqtt_msg)
          );

          SELECT create_hypertable('$UNS_historian__table', 'time');
          " | PGPASSWORD=${UNS_historian__password} psql -h ${UNS_historian__hostname} -U $UNS_historian__username -d $UNS_historian__database  -p 5432

      - name: Run all type of tests
        uses: ./.github/include/execute_tests/
        timeout-minutes: 3
        with:
          module: 07_uns_graphql
          integration_tests: true
          SAFETY_API_KEY: ${{ secrets.SAFETY_API_KEY }}
          pytest_flags: ${{ inputs.pytest_add_opts }}
          test_by_directory: true
      - name: Create graphQL schema
        env:
          # schema_file: "./schema/uns_schema.graphql"
          schema_file: "07_uns_graphql/schema/uns_schema.graphql"
        run: |
          #cd 07_uns_graphql
          # create the schema
          uv run strawberry export-schema \
            uns_graphql.uns_graphql_app:UNSGraphql.schema  \
            --output $schema_file

          if git diff --quiet -- "$schema_file"; then
            echo "Schema Unchanged"
          else
            # check in the modified file
            git config --global user.email "actions@github.com"
            git config --global user.name "Github Actions"
            # Ensure that this check-in does not triggering another build
            git add $schema_file
            git commit -m "updated schema file for graphql api"
          fi

  build_docker:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v6

      - name: Compile and Test Dockerfile
        uses: ./.github/include/test_docker_builds/
        with:
          module: 07_uns_graphql
          image_name: uns/graphql
